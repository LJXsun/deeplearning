{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from solver import Solver\n",
    "from visualize import plot_loss_and_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10608743 -0.10608743 -0.10608743 ... -0.10608743 -0.10608743\n",
      "  -0.10608743]\n",
      " [-0.13611445 -0.13611445 -0.13611445 ... -0.13611445 -0.13611445\n",
      "  -0.13611445]\n",
      " [-0.15166066 -0.15166066 -0.15166066 ... -0.15166066 -0.15166066\n",
      "  -0.15166066]\n",
      " ...\n",
      " [-0.08621449 -0.08621449 -0.08621449 ... -0.08621449 -0.08621449\n",
      "  -0.08621449]\n",
      " [-0.11283013 -0.11283013 -0.11283013 ... -0.11283013 -0.11283013\n",
      "  -0.11283013]\n",
      " [-0.15661765 -0.15661765 -0.15661765 ... -0.15661765 -0.15661765\n",
      "  -0.15661765]]\n",
      "<class 'numpy.ndarray'>\n",
      "[5 6 6 3 9 7 1 4 9 3 4 1 3 3 7 8 3 2 4 1 0 0 1 7 5 1 5 1 1 4 0 8 9 4 7 8 3\n",
      " 6 5 8 8 5 1 9 1 2 5 7 4 0 1 5 8 4 4 9 2 7 5 8 8 2 5 5 2 6 4 2 4 8 6 3 7 6\n",
      " 7 5 2 9 6 1 9 3 0 8 9 2 0 7 6 7 1 6 3 7 3 4 3 6 9 8]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "Epoch [0]\t Average training loss nan\t Average training accuracy nan\n",
      "Epoch [0]\t Average validation loss 0.0000\t Average validation accuracy 0.0000\n",
      "\n",
      "Epoch [1][10]\t Batch [0][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [50][550]\t Training Loss 0.0000\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Work\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "F:\\Work\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][10]\t Batch [100][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [150][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [200][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [250][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [300][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [350][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [400][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [450][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [500][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "\n",
      "Epoch [1]\t Average training loss 0.0000\t Average training accuracy 0.0000\n",
      "Epoch [1]\t Average validation loss 0.0000\t Average validation accuracy 0.0000\n",
      "\n",
      "Epoch [2][10]\t Batch [0][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [50][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [100][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [150][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [200][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [250][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [300][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [350][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [400][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [450][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [500][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "\n",
      "Epoch [2]\t Average training loss 0.0000\t Average training accuracy 0.0000\n",
      "Epoch [2]\t Average validation loss 0.0000\t Average validation accuracy 0.0000\n",
      "\n",
      "Epoch [3][10]\t Batch [0][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [50][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [100][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [150][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [200][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [250][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [300][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [350][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [400][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [450][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [500][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "\n",
      "Epoch [3]\t Average training loss 0.0000\t Average training accuracy 0.0000\n",
      "Epoch [3]\t Average validation loss 0.0000\t Average validation accuracy 0.0000\n",
      "\n",
      "Epoch [4][10]\t Batch [0][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [50][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [100][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [150][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [200][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [250][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [300][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [350][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [400][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [450][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [500][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "\n",
      "Epoch [4]\t Average training loss 0.0000\t Average training accuracy 0.0000\n",
      "Epoch [4]\t Average validation loss 0.0000\t Average validation accuracy 0.0000\n",
      "\n",
      "Epoch [5][10]\t Batch [0][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [50][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [100][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [150][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [200][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [250][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [300][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [350][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [400][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [450][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [500][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "\n",
      "Epoch [5]\t Average training loss 0.0000\t Average training accuracy 0.0000\n",
      "Epoch [5]\t Average validation loss 0.0000\t Average validation accuracy 0.0000\n",
      "\n",
      "Epoch [6][10]\t Batch [0][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [50][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [100][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [150][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [200][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [250][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [300][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [350][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [400][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [450][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [500][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "\n",
      "Epoch [6]\t Average training loss 0.0000\t Average training accuracy 0.0000\n",
      "Epoch [6]\t Average validation loss 0.0000\t Average validation accuracy 0.0000\n",
      "\n",
      "Epoch [7][10]\t Batch [0][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [50][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [100][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [150][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [200][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [250][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [300][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [350][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [400][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [450][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [500][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "\n",
      "Epoch [7]\t Average training loss 0.0000\t Average training accuracy 0.0000\n",
      "Epoch [7]\t Average validation loss 0.0000\t Average validation accuracy 0.0000\n",
      "\n",
      "Epoch [8][10]\t Batch [0][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [50][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [100][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [150][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [200][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [250][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [300][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [350][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [400][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [450][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [500][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "\n",
      "Epoch [8]\t Average training loss 0.0000\t Average training accuracy 0.0000\n",
      "Epoch [8]\t Average validation loss 0.0000\t Average validation accuracy 0.0000\n",
      "\n",
      "Epoch [9][10]\t Batch [0][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [50][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [100][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [150][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [200][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [250][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [300][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [350][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [400][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [450][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [500][550]\t Training Loss 0.0000\t Accuracy 0.0000\n",
      "\n",
      "Epoch [9]\t Average training loss 0.0000\t Average training accuracy 0.0000\n",
      "Epoch [9]\t Average validation loss 0.0000\t Average validation accuracy 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train without momentum\n",
    "cfg = {\n",
    "    'data_root': 'data',\n",
    "    'max_epoch': 1,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'momentum': 0,\n",
    "    'display_freq': 50,\n",
    "}\n",
    "\n",
    "runner = Solver(cfg)\n",
    "loss1, acc1 = runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = runner.test()\n",
    "print('Final test accuracy {:.4f}\\n'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with momentum\n",
    "cfg = {\n",
    "    'data_root': 'data',\n",
    "    'max_epoch': 10,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'display_freq': 50,\n",
    "}\n",
    "\n",
    "runner = Solver(cfg)\n",
    "loss2, acc2 = runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = runner.test()\n",
    "print('Final test accuracy {:.4f}\\n'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_and_acc({\n",
    "    \"momentum=0\": [loss1, acc1],\n",
    "    \"momentum=0.9\": [loss2, acc2]\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
